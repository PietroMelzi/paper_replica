{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA FROM AFPDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFPDB - Train labels size:  4800\n",
      "AFPDB - Test labels size:   1200\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "font_csvs =  [str(p) for p in pathlib.Path('preproc_data/afpdb').glob(\"*.csv\")]\n",
    "train_csvs = font_csvs[0:40]+font_csvs[50:90]\n",
    "test_csvs = font_csvs[40:50]+font_csvs[90:100]\n",
    "afpdb_train_labels = np.array([0]*40*60+[1]*40*60)\n",
    "afpdb_test_labels = np.array([0]*10*60+[1]*10*60)\n",
    "print(\"AFPDB - Train labels size: \", afpdb_train_labels.size)\n",
    "print(\"AFPDB - Test labels size:  \", afpdb_test_labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFPDB - Train data shape:  (4800, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "afpdb_train_data = np.array([])\n",
    "for csv in train_csvs:\n",
    "    data = pd.read_csv(csv, header=None)\n",
    "    for c in range(data.shape[1]):\n",
    "        row = np.array([np.array([data.iloc[:, c]])])\n",
    "        if afpdb_train_data.shape[0] == 0:\n",
    "            afpdb_train_data = row\n",
    "        else:\n",
    "            afpdb_train_data = np.vstack((afpdb_train_data, row))\n",
    "afpdb_train_data = np.moveaxis(afpdb_train_data, 1, 2)\n",
    "print(\"AFPDB - Train data shape: \", afpdb_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFPDB - Test data shape:  (1200, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "afpdb_test_data = np.array([])\n",
    "for csv in test_csvs:\n",
    "    data = pd.read_csv(csv, header=None)\n",
    "    for c in range(data.shape[1]):\n",
    "        row = np.array([np.array([data.iloc[:, c]])])\n",
    "        if afpdb_test_data.shape[0] == 0:\n",
    "            afpdb_test_data = row\n",
    "        else:\n",
    "            afpdb_test_data = np.vstack((afpdb_test_data, row))\n",
    "afpdb_test_data = np.moveaxis(afpdb_test_data, 1, 2)\n",
    "print(\"AFPDB - Test data shape: \", afpdb_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA FROM AFDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFDB data shape:  (3419, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "afdb_csvs =  [str(p) for p in pathlib.Path('preproc_data/afdb').glob(\"*.csv\")]\n",
    "afdb_data = np.array([])\n",
    "for csv in afdb_csvs:\n",
    "    data = pd.read_csv(csv, header=None)\n",
    "    for c in range(data.shape[1]):\n",
    "        row = np.array([np.array([data.iloc[:, c]])])\n",
    "        if afdb_data.shape[0] == 0:\n",
    "            afdb_data = row\n",
    "        else:\n",
    "            afdb_data = np.vstack((afdb_data, row))\n",
    "afdb_data = np.moveaxis(afdb_data, 1, 2)\n",
    "print(\"AFDB data shape: \", afdb_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFDB - Train data shape:  (2736, 900, 1)\n",
      "AFDB - Test data shape:   (683, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "TEST_PROP = 0.8\n",
    "index_split = math.ceil(afdb_data.shape[0] * TEST_PROP)\n",
    "afdb_train = afdb_data[:index_split,:,:]\n",
    "afdb_test = afdb_data[index_split:,:,:]\n",
    "print(\"AFDB - Train data shape: \", afdb_train.shape)\n",
    "print(\"AFDB - Test data shape:  \", afdb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total - Train labels size:  7536\n",
      "Total - Test labels size:   1883\n"
     ]
    }
   ],
   "source": [
    "afdb_train_labels = np.array([1]*afdb_train.shape[0])\n",
    "afdb_test_labels = np.array([1]*afdb_test.shape[0])\n",
    "train_labels = np.concatenate((afpdb_train_labels, afdb_train_labels))\n",
    "test_labels = np.concatenate((afpdb_test_labels, afdb_test_labels))\n",
    "print(\"Total - Train labels size: \", train_labels.size)\n",
    "print(\"Total - Test labels size:  \", test_labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total - Train data shape:  (7536, 900, 1)\n",
      "Total - Test data shape:  (1883, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.concatenate((afpdb_train_data, afdb_train))\n",
    "test_data = np.concatenate((afpdb_test_data, afdb_test))\n",
    "print(\"Total - Train data shape: \", train_data.shape)\n",
    "print(\"Total - Test data shape: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA FROM NSRDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSRDB data shape:  (3420, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "nsrdb_csvs =  [str(p) for p in pathlib.Path('preproc_data/nsrdb').glob(\"*.csv\")]\n",
    "nsrdb_data = np.array([])\n",
    "for csv in nsrdb_csvs:\n",
    "    data = pd.read_csv(csv, header=None)\n",
    "    for c in range(data.shape[1]):\n",
    "        row = np.array([np.array([data.iloc[:, c]])])\n",
    "        if nsrdb_data.shape[0] == 0:\n",
    "            nsrdb_data = row\n",
    "        else:\n",
    "            nsrdb_data = np.vstack((nsrdb_data, row))\n",
    "nsrdb_data = np.moveaxis(nsrdb_data, 1, 2)\n",
    "print(\"NSRDB data shape: \", nsrdb_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSRDB - Train data shape:  (2736, 900, 1)\n",
      "NSRDB - Test data shape:   (684, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "index_split = math.ceil(nsrdb_data.shape[0] * TEST_PROP)\n",
    "nsrdb_train = nsrdb_data[:index_split,:,:]\n",
    "nsrdb_test = nsrdb_data[index_split:,:,:]\n",
    "print(\"NSRDB - Train data shape: \", nsrdb_train.shape)\n",
    "print(\"NSRDB - Test data shape:  \", nsrdb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total - Train labels size:  10272\n",
      "Total - Test labels size:   2567\n"
     ]
    }
   ],
   "source": [
    "nsrdb_train_labels = np.array([0]*nsrdb_train.shape[0])\n",
    "nsrdb_test_labels = np.array([0]*nsrdb_test.shape[0])\n",
    "train_labels2 = np.concatenate((train_labels, nsrdb_train_labels))\n",
    "test_labels2 = np.concatenate((test_labels, nsrdb_test_labels))\n",
    "print(\"Total - Train labels size: \", train_labels2.size)\n",
    "print(\"Total - Test labels size:  \", test_labels2.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total - Train data shape:  (10272, 900, 1)\n",
      "Total - Test data shape:   (2567, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data2 = np.concatenate((train_data, nsrdb_train))\n",
    "test_data2 = np.concatenate((test_data, nsrdb_test))\n",
    "print(\"Total - Train data shape: \", train_data2.shape)\n",
    "print(\"Total - Test data shape:  \", test_data2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD DATASET OBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch size:  (2, 900, 1)\n",
      "Labels batch size:  (2,)\n"
     ]
    }
   ],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((train_data2, train_labels2))\n",
    "test = tf.data.Dataset.from_tensor_slices((test_data2, test_labels2))\n",
    "\n",
    "train = train.shuffle(len(train)).batch(2)\n",
    "test = test.batch(16)\n",
    "\n",
    "for d, l in train.take(1):\n",
    "    print (\"Data batch size:   \", d.shape)\n",
    "    print (\"Labels batch size: \", l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 900, 1)            4         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 893, 16)           144       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 446, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 446, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 443, 32)           2080      \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 440, 32)           4128      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 220, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 220, 32)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 220, 16)           528       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 110, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 110, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 109, 32)           1056      \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 108, 32)           2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 54, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 54, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 54, 8)             264       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 866       \n",
      "=================================================================\n",
      "Total params: 11,150\n",
      "Trainable params: 11,148\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.BatchNormalization(input_shape=(900,1)))\n",
    "model.add(layers.Conv1D(16,8))\n",
    "\n",
    "model.add(layers.MaxPool1D(strides=2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv1D(32,4))\n",
    "model.add(layers.Conv1D(32,4))\n",
    "model.add(layers.MaxPool1D(strides=2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPool1D(strides=2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv1D(32,2))\n",
    "model.add(layers.Conv1D(32,2))\n",
    "model.add(layers.MaxPool1D(strides=2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(2))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.6446 - accuracy: 0.6199 - val_loss: 0.6301 - val_accuracy: 0.6436\n",
      "Epoch 2/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.5437 - accuracy: 0.7309 - val_loss: 0.7107 - val_accuracy: 0.5621\n",
      "Epoch 3/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.4965 - accuracy: 0.7598 - val_loss: 0.8937 - val_accuracy: 0.5972\n",
      "Epoch 4/200\n",
      "5136/5136 [==============================] - 46s 9ms/step - loss: 0.4700 - accuracy: 0.7771 - val_loss: 0.6668 - val_accuracy: 0.6272\n",
      "Epoch 5/200\n",
      "5136/5136 [==============================] - 46s 9ms/step - loss: 0.4418 - accuracy: 0.7992 - val_loss: 0.6362 - val_accuracy: 0.6712\n",
      "Epoch 6/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.4211 - accuracy: 0.8078 - val_loss: 0.6632 - val_accuracy: 0.6977\n",
      "Epoch 7/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.4146 - accuracy: 0.8143 - val_loss: 0.9026 - val_accuracy: 0.4632\n",
      "Epoch 8/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.3937 - accuracy: 0.8252 - val_loss: 0.7519 - val_accuracy: 0.6194\n",
      "Epoch 9/200\n",
      "5136/5136 [==============================] - 46s 9ms/step - loss: 0.3864 - accuracy: 0.8328 - val_loss: 0.7482 - val_accuracy: 0.6369\n",
      "Epoch 10/200\n",
      "5136/5136 [==============================] - 47s 9ms/step - loss: 0.3754 - accuracy: 0.8398 - val_loss: 0.7212 - val_accuracy: 0.6619\n",
      "Epoch 11/200\n",
      "5136/5136 [==============================] - 46s 9ms/step - loss: 0.3646 - accuracy: 0.8436 - val_loss: 0.7904 - val_accuracy: 0.6101\n",
      "Epoch 12/200\n",
      "5136/5136 [==============================] - 48s 9ms/step - loss: 0.3586 - accuracy: 0.8467 - val_loss: 0.9188 - val_accuracy: 0.5668\n",
      "Epoch 13/200\n",
      "5136/5136 [==============================] - 50s 10ms/step - loss: 0.3531 - accuracy: 0.8520 - val_loss: 0.7382 - val_accuracy: 0.6428\n",
      "Epoch 14/200\n",
      "5136/5136 [==============================] - 47s 9ms/step - loss: 0.3402 - accuracy: 0.8594 - val_loss: 0.7908 - val_accuracy: 0.6295\n",
      "Epoch 15/200\n",
      "5136/5136 [==============================] - 47s 9ms/step - loss: 0.3435 - accuracy: 0.8556 - val_loss: 0.7872 - val_accuracy: 0.6899\n",
      "Epoch 16/200\n",
      "5136/5136 [==============================] - 46s 9ms/step - loss: 0.3330 - accuracy: 0.8597 - val_loss: 0.7935 - val_accuracy: 0.6654\n",
      "Epoch 17/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.3232 - accuracy: 0.8639 - val_loss: 0.8607 - val_accuracy: 0.6139\n",
      "Epoch 18/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.3177 - accuracy: 0.8706 - val_loss: 1.0736 - val_accuracy: 0.6541\n",
      "Epoch 19/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.3133 - accuracy: 0.8705 - val_loss: 1.0501 - val_accuracy: 0.6439\n",
      "Epoch 20/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.3111 - accuracy: 0.8721 - val_loss: 1.0684 - val_accuracy: 0.6899\n",
      "Epoch 21/200\n",
      "5136/5136 [==============================] - 47s 9ms/step - loss: 0.3130 - accuracy: 0.8709 - val_loss: 0.9149 - val_accuracy: 0.5980\n",
      "Epoch 22/200\n",
      "5136/5136 [==============================] - 42s 8ms/step - loss: 0.3076 - accuracy: 0.8715 - val_loss: 0.8829 - val_accuracy: 0.5914\n",
      "Epoch 23/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.3045 - accuracy: 0.8757 - val_loss: 0.8034 - val_accuracy: 0.6556\n",
      "Epoch 24/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.3009 - accuracy: 0.8744 - val_loss: 0.8230 - val_accuracy: 0.6354\n",
      "Epoch 25/200\n",
      "5136/5136 [==============================] - 42s 8ms/step - loss: 0.2914 - accuracy: 0.8791 - val_loss: 0.7652 - val_accuracy: 0.6350\n",
      "Epoch 26/200\n",
      "5136/5136 [==============================] - 42s 8ms/step - loss: 0.3034 - accuracy: 0.8732 - val_loss: 0.9540 - val_accuracy: 0.6350\n",
      "Epoch 27/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2936 - accuracy: 0.8808 - val_loss: 0.9313 - val_accuracy: 0.5890\n",
      "Epoch 28/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2895 - accuracy: 0.8821 - val_loss: 0.9490 - val_accuracy: 0.6139\n",
      "Epoch 29/200\n",
      "5136/5136 [==============================] - 46s 9ms/step - loss: 0.2920 - accuracy: 0.8828 - val_loss: 0.8338 - val_accuracy: 0.6716\n",
      "Epoch 30/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2884 - accuracy: 0.8818 - val_loss: 0.9224 - val_accuracy: 0.6817\n",
      "Epoch 31/200\n",
      "5136/5136 [==============================] - 46s 9ms/step - loss: 0.2874 - accuracy: 0.8858 - val_loss: 0.8968 - val_accuracy: 0.6116\n",
      "Epoch 32/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.2872 - accuracy: 0.8853 - val_loss: 0.8857 - val_accuracy: 0.6599\n",
      "Epoch 33/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.2860 - accuracy: 0.8850 - val_loss: 1.0299 - val_accuracy: 0.5917\n",
      "Epoch 34/200\n",
      "5136/5136 [==============================] - 43s 8ms/step - loss: 0.2767 - accuracy: 0.8855 - val_loss: 0.9595 - val_accuracy: 0.6362\n",
      "Epoch 35/200\n",
      "5136/5136 [==============================] - 43s 8ms/step - loss: 0.2844 - accuracy: 0.8813 - val_loss: 1.0452 - val_accuracy: 0.5840\n",
      "Epoch 36/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.2746 - accuracy: 0.8889 - val_loss: 1.0599 - val_accuracy: 0.6455\n",
      "Epoch 37/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2753 - accuracy: 0.8897 - val_loss: 0.8875 - val_accuracy: 0.6260\n",
      "Epoch 38/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.2760 - accuracy: 0.8873 - val_loss: 1.1028 - val_accuracy: 0.5937\n",
      "Epoch 39/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2707 - accuracy: 0.8876 - val_loss: 0.9670 - val_accuracy: 0.5914\n",
      "Epoch 40/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.2712 - accuracy: 0.8899 - val_loss: 0.8467 - val_accuracy: 0.6529\n",
      "Epoch 41/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.2772 - accuracy: 0.8876 - val_loss: 1.0631 - val_accuracy: 0.6237\n",
      "Epoch 42/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2637 - accuracy: 0.8946 - val_loss: 0.8487 - val_accuracy: 0.6463\n",
      "Epoch 43/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2698 - accuracy: 0.8902 - val_loss: 0.9921 - val_accuracy: 0.6058\n",
      "Epoch 44/200\n",
      "5136/5136 [==============================] - 45s 9ms/step - loss: 0.2595 - accuracy: 0.8940 - val_loss: 1.1766 - val_accuracy: 0.5925\n",
      "Epoch 45/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2674 - accuracy: 0.8932 - val_loss: 1.1584 - val_accuracy: 0.6389\n",
      "Epoch 46/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2590 - accuracy: 0.8954 - val_loss: 0.9817 - val_accuracy: 0.6128\n",
      "Epoch 47/200\n",
      "5136/5136 [==============================] - 44s 8ms/step - loss: 0.2610 - accuracy: 0.8944 - val_loss: 0.9252 - val_accuracy: 0.6884\n",
      "Epoch 48/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2643 - accuracy: 0.8927 - val_loss: 1.0580 - val_accuracy: 0.6276\n",
      "Epoch 49/200\n",
      "5136/5136 [==============================] - 44s 8ms/step - loss: 0.2619 - accuracy: 0.8922 - val_loss: 1.0327 - val_accuracy: 0.6264\n",
      "Epoch 50/200\n",
      "5136/5136 [==============================] - 44s 9ms/step - loss: 0.2556 - accuracy: 0.8972 - val_loss: 1.0359 - val_accuracy: 0.5777\n",
      "Epoch 51/200\n",
      "5136/5136 [==============================] - 46s 9ms/step - loss: 0.2555 - accuracy: 0.8982 - val_loss: 1.0597 - val_accuracy: 0.6467\n",
      "Epoch 52/200\n",
      "5136/5136 [==============================] - 46s 9ms/step - loss: 0.2575 - accuracy: 0.8960 - val_loss: 1.0255 - val_accuracy: 0.6190\n",
      "Epoch 53/200\n",
      "5136/5136 [==============================] - 47s 9ms/step - loss: 0.2456 - accuracy: 0.8969 - val_loss: 1.1617 - val_accuracy: 0.5773\n",
      "Epoch 54/200\n",
      "5136/5136 [==============================] - 49s 10ms/step - loss: 0.2540 - accuracy: 0.9017 - val_loss: 0.8976 - val_accuracy: 0.5968\n",
      "Epoch 55/200\n",
      "5136/5136 [==============================] - 46s 9ms/step - loss: 0.2494 - accuracy: 0.9014 - val_loss: 1.2399 - val_accuracy: 0.6420\n",
      "Epoch 56/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2498 - accuracy: 0.8983 - val_loss: 1.2023 - val_accuracy: 0.6194\n",
      "Epoch 57/200\n",
      "5136/5136 [==============================] - 42s 8ms/step - loss: 0.2514 - accuracy: 0.8992 - val_loss: 0.9825 - val_accuracy: 0.6397\n",
      "Epoch 58/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2437 - accuracy: 0.9055 - val_loss: 1.1441 - val_accuracy: 0.6595\n",
      "Epoch 59/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2611 - accuracy: 0.8988 - val_loss: 1.2374 - val_accuracy: 0.5668\n",
      "Epoch 60/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2539 - accuracy: 0.8966 - val_loss: 1.2403 - val_accuracy: 0.6358\n",
      "Epoch 61/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2495 - accuracy: 0.8978 - val_loss: 0.8539 - val_accuracy: 0.6634\n",
      "Epoch 62/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2477 - accuracy: 0.9001 - val_loss: 0.9909 - val_accuracy: 0.6065\n",
      "Epoch 63/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2437 - accuracy: 0.9023 - val_loss: 1.3234 - val_accuracy: 0.5855\n",
      "Epoch 64/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2474 - accuracy: 0.9017 - val_loss: 1.0198 - val_accuracy: 0.6311\n",
      "Epoch 65/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2400 - accuracy: 0.9065 - val_loss: 1.0194 - val_accuracy: 0.5863\n",
      "Epoch 66/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2384 - accuracy: 0.9015 - val_loss: 0.9871 - val_accuracy: 0.6685\n",
      "Epoch 67/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2435 - accuracy: 0.9000 - val_loss: 0.8340 - val_accuracy: 0.6693\n",
      "Epoch 68/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2395 - accuracy: 0.9031 - val_loss: 1.0176 - val_accuracy: 0.6876\n",
      "Epoch 69/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2358 - accuracy: 0.9046 - val_loss: 1.0316 - val_accuracy: 0.5641\n",
      "Epoch 70/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2336 - accuracy: 0.9057 - val_loss: 1.3056 - val_accuracy: 0.5882\n",
      "Epoch 71/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2320 - accuracy: 0.9066 - val_loss: 0.9389 - val_accuracy: 0.6101\n",
      "Epoch 72/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2394 - accuracy: 0.9046 - val_loss: 1.1100 - val_accuracy: 0.5917\n",
      "Epoch 73/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2543 - accuracy: 0.9034 - val_loss: 1.2746 - val_accuracy: 0.5617\n",
      "Epoch 74/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2369 - accuracy: 0.9044 - val_loss: 1.2868 - val_accuracy: 0.5804\n",
      "Epoch 75/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2317 - accuracy: 0.9063 - val_loss: 1.3090 - val_accuracy: 0.5820\n",
      "Epoch 76/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2315 - accuracy: 0.9086 - val_loss: 1.1267 - val_accuracy: 0.5843\n",
      "Epoch 77/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2299 - accuracy: 0.9078 - val_loss: 1.2256 - val_accuracy: 0.6065\n",
      "Epoch 78/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2347 - accuracy: 0.9071 - val_loss: 1.2930 - val_accuracy: 0.5886\n",
      "Epoch 79/200\n",
      "5136/5136 [==============================] - 42s 8ms/step - loss: 0.2307 - accuracy: 0.9082 - val_loss: 1.0429 - val_accuracy: 0.6338\n",
      "Epoch 80/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2362 - accuracy: 0.9062 - val_loss: 1.0106 - val_accuracy: 0.6295\n",
      "Epoch 81/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2300 - accuracy: 0.9070 - val_loss: 1.0532 - val_accuracy: 0.5781\n",
      "Epoch 82/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2363 - accuracy: 0.9050 - val_loss: 1.3781 - val_accuracy: 0.6065\n",
      "Epoch 83/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2294 - accuracy: 0.9057 - val_loss: 1.1384 - val_accuracy: 0.6167\n",
      "Epoch 84/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2297 - accuracy: 0.9110 - val_loss: 1.1110 - val_accuracy: 0.5898\n",
      "Epoch 85/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2192 - accuracy: 0.9124 - val_loss: 1.2339 - val_accuracy: 0.6323\n",
      "Epoch 86/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2227 - accuracy: 0.9116 - val_loss: 1.1273 - val_accuracy: 0.6249\n",
      "Epoch 87/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2195 - accuracy: 0.9112 - val_loss: 0.9003 - val_accuracy: 0.6638\n",
      "Epoch 88/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2351 - accuracy: 0.9077 - val_loss: 1.3203 - val_accuracy: 0.5921\n",
      "Epoch 89/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2228 - accuracy: 0.9110 - val_loss: 1.2042 - val_accuracy: 0.6139\n",
      "Epoch 90/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2270 - accuracy: 0.9111 - val_loss: 0.9753 - val_accuracy: 0.6326\n",
      "Epoch 91/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2210 - accuracy: 0.9109 - val_loss: 0.9499 - val_accuracy: 0.6132\n",
      "Epoch 92/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2239 - accuracy: 0.9112 - val_loss: 1.0928 - val_accuracy: 0.6077\n",
      "Epoch 93/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2225 - accuracy: 0.9094 - val_loss: 1.0173 - val_accuracy: 0.6190\n",
      "Epoch 94/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2163 - accuracy: 0.9171 - val_loss: 1.3338 - val_accuracy: 0.5991\n",
      "Epoch 95/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2190 - accuracy: 0.9143 - val_loss: 1.1937 - val_accuracy: 0.6665\n",
      "Epoch 96/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2226 - accuracy: 0.9123 - val_loss: 1.0508 - val_accuracy: 0.6276\n",
      "Epoch 97/200\n",
      "5136/5136 [==============================] - 41s 8ms/step - loss: 0.2212 - accuracy: 0.9142 - val_loss: 1.2266 - val_accuracy: 0.5337\n",
      "Epoch 98/200\n",
      "5136/5136 [==============================] - 43s 8ms/step - loss: 0.2199 - accuracy: 0.9100 - val_loss: 0.9656 - val_accuracy: 0.6256\n",
      "Epoch 99/200\n",
      "5136/5136 [==============================] - 42s 8ms/step - loss: 0.2202 - accuracy: 0.9111 - val_loss: 1.0571 - val_accuracy: 0.6611\n",
      "Epoch 100/200\n",
      "5136/5136 [==============================] - 8925s 2s/step - loss: 0.2127 - accuracy: 0.9184 - val_loss: 1.0451 - val_accuracy: 0.6545\n",
      "Epoch 101/200\n",
      "5136/5136 [==============================] - 55s 11ms/step - loss: 0.2182 - accuracy: 0.9130 - val_loss: 1.2587 - val_accuracy: 0.5984\n",
      "Epoch 102/200\n",
      "5136/5136 [==============================] - 56s 11ms/step - loss: 0.2169 - accuracy: 0.9143 - val_loss: 1.0600 - val_accuracy: 0.6058\n",
      "Epoch 103/200\n",
      "5136/5136 [==============================] - 54s 11ms/step - loss: 0.2176 - accuracy: 0.9131 - val_loss: 1.3732 - val_accuracy: 0.6065\n",
      "Epoch 104/200\n",
      "5136/5136 [==============================] - 53s 10ms/step - loss: 0.2151 - accuracy: 0.9135 - val_loss: 1.3548 - val_accuracy: 0.6272\n",
      "Epoch 105/200\n",
      "5136/5136 [==============================] - 53s 10ms/step - loss: 0.2172 - accuracy: 0.9133 - val_loss: 1.2046 - val_accuracy: 0.6011\n",
      "Epoch 106/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2169 - accuracy: 0.9142 - val_loss: 1.1059 - val_accuracy: 0.6217\n",
      "Epoch 107/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2163 - accuracy: 0.9152 - val_loss: 1.0532 - val_accuracy: 0.5571\n",
      "Epoch 108/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2146 - accuracy: 0.9157 - val_loss: 1.3028 - val_accuracy: 0.6428\n",
      "Epoch 109/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2137 - accuracy: 0.9192 - val_loss: 1.1676 - val_accuracy: 0.6139\n",
      "Epoch 110/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2132 - accuracy: 0.9145 - val_loss: 1.2431 - val_accuracy: 0.6116\n",
      "Epoch 111/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2173 - accuracy: 0.9144 - val_loss: 1.0421 - val_accuracy: 0.6545\n",
      "Epoch 112/200\n",
      "5136/5136 [==============================] - 64s 12ms/step - loss: 0.2146 - accuracy: 0.9164 - val_loss: 1.2323 - val_accuracy: 0.5773\n",
      "Epoch 113/200\n",
      "5136/5136 [==============================] - 58s 11ms/step - loss: 0.2151 - accuracy: 0.9154 - val_loss: 1.0661 - val_accuracy: 0.6268\n",
      "Epoch 114/200\n",
      "5136/5136 [==============================] - 58s 11ms/step - loss: 0.2097 - accuracy: 0.9191 - val_loss: 1.3377 - val_accuracy: 0.6295\n",
      "Epoch 115/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2146 - accuracy: 0.9150 - val_loss: 1.0285 - val_accuracy: 0.6677\n",
      "Epoch 116/200\n",
      "5136/5136 [==============================] - 58s 11ms/step - loss: 0.2083 - accuracy: 0.9173 - val_loss: 0.8518 - val_accuracy: 0.6101\n",
      "Epoch 117/200\n",
      "5136/5136 [==============================] - 58s 11ms/step - loss: 0.2117 - accuracy: 0.9157 - val_loss: 1.0806 - val_accuracy: 0.6089\n",
      "Epoch 118/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2140 - accuracy: 0.9192 - val_loss: 1.4896 - val_accuracy: 0.5929\n",
      "Epoch 119/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2126 - accuracy: 0.9173 - val_loss: 1.3709 - val_accuracy: 0.5980\n",
      "Epoch 120/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2091 - accuracy: 0.9197 - val_loss: 1.3737 - val_accuracy: 0.6377\n",
      "Epoch 121/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2066 - accuracy: 0.9190 - val_loss: 1.4294 - val_accuracy: 0.6050\n",
      "Epoch 122/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2124 - accuracy: 0.9153 - val_loss: 1.0350 - val_accuracy: 0.6007\n",
      "Epoch 123/200\n",
      "5136/5136 [==============================] - 59s 11ms/step - loss: 0.2066 - accuracy: 0.9203 - val_loss: 0.9525 - val_accuracy: 0.6338\n",
      "Epoch 124/200\n",
      "5136/5136 [==============================] - 59s 11ms/step - loss: 0.2094 - accuracy: 0.9184 - val_loss: 1.1565 - val_accuracy: 0.6108\n",
      "Epoch 125/200\n",
      "5136/5136 [==============================] - 58s 11ms/step - loss: 0.2094 - accuracy: 0.9173 - val_loss: 1.1726 - val_accuracy: 0.5906\n",
      "Epoch 126/200\n",
      "5136/5136 [==============================] - 65s 13ms/step - loss: 0.2045 - accuracy: 0.9201 - val_loss: 1.3519 - val_accuracy: 0.6408\n",
      "Epoch 127/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2102 - accuracy: 0.9181 - val_loss: 1.1261 - val_accuracy: 0.6486\n",
      "Epoch 128/200\n",
      "5136/5136 [==============================] - 59s 11ms/step - loss: 0.2099 - accuracy: 0.9189 - val_loss: 0.8283 - val_accuracy: 0.6552\n",
      "Epoch 129/200\n",
      "5136/5136 [==============================] - 59s 11ms/step - loss: 0.2172 - accuracy: 0.9147 - val_loss: 1.1156 - val_accuracy: 0.6097\n",
      "Epoch 130/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2104 - accuracy: 0.9171 - val_loss: 1.1674 - val_accuracy: 0.5890\n",
      "Epoch 131/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2122 - accuracy: 0.9183 - val_loss: 1.2951 - val_accuracy: 0.6603\n",
      "Epoch 132/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2139 - accuracy: 0.9175 - val_loss: 1.2664 - val_accuracy: 0.6291\n",
      "Epoch 133/200\n",
      "5136/5136 [==============================] - 59s 11ms/step - loss: 0.2113 - accuracy: 0.9113 - val_loss: 1.0763 - val_accuracy: 0.6046\n",
      "Epoch 134/200\n",
      "5136/5136 [==============================] - 59s 12ms/step - loss: 0.2095 - accuracy: 0.9154 - val_loss: 1.3677 - val_accuracy: 0.6163\n",
      "Epoch 135/200\n",
      "5136/5136 [==============================] - 59s 12ms/step - loss: 0.2046 - accuracy: 0.9188 - val_loss: 1.2609 - val_accuracy: 0.6252\n",
      "Epoch 136/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2069 - accuracy: 0.9179 - val_loss: 1.2433 - val_accuracy: 0.6537\n",
      "Epoch 137/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2090 - accuracy: 0.9194 - val_loss: 1.1172 - val_accuracy: 0.5890\n",
      "Epoch 138/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2073 - accuracy: 0.9205 - val_loss: 1.3476 - val_accuracy: 0.6116\n",
      "Epoch 139/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2100 - accuracy: 0.9159 - val_loss: 1.2930 - val_accuracy: 0.6241\n",
      "Epoch 140/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2168 - accuracy: 0.9184 - val_loss: 0.9986 - val_accuracy: 0.6256\n",
      "Epoch 141/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2085 - accuracy: 0.9170 - val_loss: 1.0222 - val_accuracy: 0.6350\n",
      "Epoch 142/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2142 - accuracy: 0.9131 - val_loss: 1.3017 - val_accuracy: 0.6284\n",
      "Epoch 143/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2072 - accuracy: 0.9180 - val_loss: 1.0263 - val_accuracy: 0.6436\n",
      "Epoch 144/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2052 - accuracy: 0.9191 - val_loss: 0.9996 - val_accuracy: 0.6845\n",
      "Epoch 145/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2098 - accuracy: 0.9169 - val_loss: 0.9583 - val_accuracy: 0.6163\n",
      "Epoch 146/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1990 - accuracy: 0.9227 - val_loss: 1.3047 - val_accuracy: 0.6810\n",
      "Epoch 147/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2072 - accuracy: 0.9202 - val_loss: 1.2720 - val_accuracy: 0.6124\n",
      "Epoch 148/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2094 - accuracy: 0.9177 - val_loss: 0.9996 - val_accuracy: 0.6213\n",
      "Epoch 149/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2117 - accuracy: 0.9154 - val_loss: 1.1564 - val_accuracy: 0.6311\n",
      "Epoch 150/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2017 - accuracy: 0.9224 - val_loss: 1.0320 - val_accuracy: 0.6186\n",
      "Epoch 151/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2090 - accuracy: 0.9210 - val_loss: 1.1155 - val_accuracy: 0.6108\n",
      "Epoch 152/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2080 - accuracy: 0.9174 - val_loss: 1.2929 - val_accuracy: 0.6404\n",
      "Epoch 153/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2037 - accuracy: 0.9176 - val_loss: 0.8788 - val_accuracy: 0.6790\n",
      "Epoch 154/200\n",
      "5136/5136 [==============================] - 60s 12ms/step - loss: 0.2073 - accuracy: 0.9159 - val_loss: 1.0132 - val_accuracy: 0.6334\n",
      "Epoch 155/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2022 - accuracy: 0.9207 - val_loss: 1.1564 - val_accuracy: 0.6139\n",
      "Epoch 156/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2060 - accuracy: 0.9180 - val_loss: 1.1680 - val_accuracy: 0.5945\n",
      "Epoch 157/200\n",
      "5136/5136 [==============================] - 63s 12ms/step - loss: 0.2076 - accuracy: 0.9191 - val_loss: 1.1281 - val_accuracy: 0.5949\n",
      "Epoch 158/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2070 - accuracy: 0.9182 - val_loss: 0.9305 - val_accuracy: 0.6619\n",
      "Epoch 159/200\n",
      "5136/5136 [==============================] - 66s 13ms/step - loss: 0.1998 - accuracy: 0.9225 - val_loss: 1.4550 - val_accuracy: 0.5968\n",
      "Epoch 160/200\n",
      "5136/5136 [==============================] - 65s 13ms/step - loss: 0.2001 - accuracy: 0.9212 - val_loss: 1.2353 - val_accuracy: 0.6069\n",
      "Epoch 161/200\n",
      "5136/5136 [==============================] - 65s 13ms/step - loss: 0.2046 - accuracy: 0.9187 - val_loss: 1.2263 - val_accuracy: 0.5902\n",
      "Epoch 162/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1995 - accuracy: 0.9228 - val_loss: 1.1119 - val_accuracy: 0.6132\n",
      "Epoch 163/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1953 - accuracy: 0.9242 - val_loss: 1.2230 - val_accuracy: 0.6175\n",
      "Epoch 164/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2059 - accuracy: 0.9160 - val_loss: 1.0564 - val_accuracy: 0.6163\n",
      "Epoch 165/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1938 - accuracy: 0.9278 - val_loss: 1.0606 - val_accuracy: 0.6774\n",
      "Epoch 166/200\n",
      "5136/5136 [==============================] - 63s 12ms/step - loss: 0.2033 - accuracy: 0.9189 - val_loss: 1.3759 - val_accuracy: 0.6903\n",
      "Epoch 167/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2051 - accuracy: 0.9192 - val_loss: 0.9896 - val_accuracy: 0.5972\n",
      "Epoch 168/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1955 - accuracy: 0.9245 - val_loss: 1.1295 - val_accuracy: 0.6245\n",
      "Epoch 169/200\n",
      "5136/5136 [==============================] - 63s 12ms/step - loss: 0.2008 - accuracy: 0.9257 - val_loss: 1.3057 - val_accuracy: 0.6007\n",
      "Epoch 170/200\n",
      "5136/5136 [==============================] - 64s 12ms/step - loss: 0.1915 - accuracy: 0.9266 - val_loss: 1.0151 - val_accuracy: 0.6023\n",
      "Epoch 171/200\n",
      "5136/5136 [==============================] - 63s 12ms/step - loss: 0.2008 - accuracy: 0.9217 - val_loss: 1.1735 - val_accuracy: 0.5801\n",
      "Epoch 172/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2022 - accuracy: 0.9214 - val_loss: 0.9974 - val_accuracy: 0.6369\n",
      "Epoch 173/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2187 - accuracy: 0.9188 - val_loss: 1.4436 - val_accuracy: 0.6233\n",
      "Epoch 174/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2012 - accuracy: 0.9222 - val_loss: 1.1358 - val_accuracy: 0.6151\n",
      "Epoch 175/200\n",
      "5136/5136 [==============================] - 63s 12ms/step - loss: 0.2035 - accuracy: 0.9183 - val_loss: 1.3162 - val_accuracy: 0.6171\n",
      "Epoch 176/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2013 - accuracy: 0.9218 - val_loss: 1.4789 - val_accuracy: 0.6065\n",
      "Epoch 177/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2105 - accuracy: 0.9191 - val_loss: 1.2028 - val_accuracy: 0.5801\n",
      "Epoch 178/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1987 - accuracy: 0.9211 - val_loss: 1.2656 - val_accuracy: 0.6268\n",
      "Epoch 179/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1929 - accuracy: 0.9230 - val_loss: 1.3497 - val_accuracy: 0.6081\n",
      "Epoch 180/200\n",
      "5136/5136 [==============================] - 63s 12ms/step - loss: 0.2031 - accuracy: 0.9231 - val_loss: 1.7976 - val_accuracy: 0.5734\n",
      "Epoch 181/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1968 - accuracy: 0.9206 - val_loss: 1.4815 - val_accuracy: 0.6171\n",
      "Epoch 182/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1998 - accuracy: 0.9225 - val_loss: 1.1467 - val_accuracy: 0.5668\n",
      "Epoch 183/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2010 - accuracy: 0.9223 - val_loss: 1.5627 - val_accuracy: 0.6167\n",
      "Epoch 184/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1957 - accuracy: 0.9237 - val_loss: 1.2810 - val_accuracy: 0.5567\n",
      "Epoch 185/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2103 - accuracy: 0.9206 - val_loss: 1.5683 - val_accuracy: 0.6393\n",
      "Epoch 186/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2123 - accuracy: 0.9187 - val_loss: 1.1036 - val_accuracy: 0.6089\n",
      "Epoch 187/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.1953 - accuracy: 0.9254 - val_loss: 1.2651 - val_accuracy: 0.6568\n",
      "Epoch 188/200\n",
      "5136/5136 [==============================] - 63s 12ms/step - loss: 0.1997 - accuracy: 0.9224 - val_loss: 1.6138 - val_accuracy: 0.6478\n",
      "Epoch 189/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2028 - accuracy: 0.9220 - val_loss: 0.9425 - val_accuracy: 0.6482\n",
      "Epoch 190/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.1944 - accuracy: 0.9223 - val_loss: 1.0296 - val_accuracy: 0.5762\n",
      "Epoch 191/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.1935 - accuracy: 0.9211 - val_loss: 1.0653 - val_accuracy: 0.6471\n",
      "Epoch 192/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.2121 - accuracy: 0.9186 - val_loss: 0.7623 - val_accuracy: 0.6416\n",
      "Epoch 193/200\n",
      "5136/5136 [==============================] - 61s 12ms/step - loss: 0.1891 - accuracy: 0.9266 - val_loss: 1.6622 - val_accuracy: 0.5793\n",
      "Epoch 194/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1996 - accuracy: 0.9243 - val_loss: 1.0021 - val_accuracy: 0.6584\n",
      "Epoch 195/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2004 - accuracy: 0.9221 - val_loss: 1.6248 - val_accuracy: 0.6459\n",
      "Epoch 196/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1960 - accuracy: 0.9239 - val_loss: 1.0911 - val_accuracy: 0.6474\n",
      "Epoch 197/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.1996 - accuracy: 0.9236 - val_loss: 1.6760 - val_accuracy: 0.6213\n",
      "Epoch 198/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2035 - accuracy: 0.9235 - val_loss: 0.8371 - val_accuracy: 0.6673\n",
      "Epoch 199/200\n",
      "5136/5136 [==============================] - 62s 12ms/step - loss: 0.2020 - accuracy: 0.9202 - val_loss: 1.0945 - val_accuracy: 0.6439\n",
      "Epoch 200/200\n",
      "5136/5136 [==============================] - 59s 11ms/step - loss: 0.1931 - accuracy: 0.9265 - val_loss: 1.3547 - val_accuracy: 0.5867\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train, epochs=200,\n",
    "                       validation_data=(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20038034220>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 - 1s - loss: 1.3547 - accuracy: 0.5867\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
