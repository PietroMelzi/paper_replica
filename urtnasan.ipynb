{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels size:  4800\n",
      "Test label size:  1200\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "font_csvs =  [str(p) for p in pathlib.Path('preproc_data/afpdb').glob(\"*.csv\")]\n",
    "train_csvs = font_csvs[0:40]+font_csvs[50:90]\n",
    "test_csvs = font_csvs[40:50]+font_csvs[90:100]\n",
    "train_labels = np.array([0]*40*60+[1]*40*60)\n",
    "test_labels = np.array([0]*10*60+[1]*10*60)\n",
    "train_labels = train_labels.reshape((-1,1))\n",
    "test_labels = test_labels.reshape((-1,1))\n",
    "print(\"Train labels size: \", train_labels.size)\n",
    "print(\"Test label size: \", test_labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 900, 1)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.array([])\n",
    "for csv in train_csvs:\n",
    "    data = pd.read_csv(csv, header=None)\n",
    "    for c in range(data.shape[1]):\n",
    "        row = np.array([np.array([data.iloc[:, c]])])\n",
    "        if train_data.shape[0] == 0:\n",
    "            train_data = row\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, row))\n",
    "train_data = np.moveaxis(train_data, 1, 2)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 900, 1)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([])\n",
    "for csv in test_csvs:\n",
    "    data = pd.read_csv(csv, header=None)\n",
    "    for c in range(data.shape[1]):\n",
    "        row = np.array([np.array([data.iloc[:, c]])])\n",
    "        if test_data.shape[0] == 0:\n",
    "            test_data = row\n",
    "        else:\n",
    "            test_data = np.vstack((test_data, row))\n",
    "test_data = np.moveaxis(test_data, 1, 2)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch size:  (2, 900, 1)\n",
      "Labels batch size:  (2, 1)\n"
     ]
    }
   ],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "test = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "\n",
    "train = train.shuffle(len(train)).batch(2)\n",
    "test = test.batch(16)\n",
    "\n",
    "for d, l in train.take(1):\n",
    "    print (\"Data batch size: \", d.shape)\n",
    "    print (\"Labels batch size: \", l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_61 (Batc (None, 900, 1)            4         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 893, 16)           144       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 446, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 446, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 443, 32)           2080      \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 440, 32)           4128      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 220, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 220, 32)           0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 220, 16)           528       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 110, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 110, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 109, 32)           1056      \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 108, 32)           2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 54, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 54, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 54, 8)             264       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 866       \n",
      "=================================================================\n",
      "Total params: 11,150\n",
      "Trainable params: 11,148\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.BatchNormalization(input_shape=(900,1)))\n",
    "model.add(layers.Conv1D(16,8))\n",
    "\n",
    "model.add(layers.MaxPool1D(strides=2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv1D(32,4))\n",
    "model.add(layers.Conv1D(32,4))\n",
    "model.add(layers.MaxPool1D(strides=2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPool1D(strides=2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv1D(32,2))\n",
    "model.add(layers.Conv1D(32,2))\n",
    "model.add(layers.MaxPool1D(strides=2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train, epochs=200,\n",
    "                       validation_data=(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test, verbose=2)\n",
    "print(\"Test loss: \", test_loss)\n",
    "Print(\"Test accuracy: \", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
